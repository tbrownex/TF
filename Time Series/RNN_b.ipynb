{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://bit.ly/2s7xoJd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tensorflow as tf\n",
    "import gcsfs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "FILE_PATH = 'ml-datasets1/TimeSeries/JenaClimate.csv'\n",
    "COLS = [\"DtTm\", \"Pressure\", \"Temp\", 'Temp(Kelv)', \"DewPt\", \"RelHumidity\",\n",
    "       \"Vapor Pressure max\", \"Vapor Pressure act\",\"Vapor Pressure def\",\n",
    "       \"SpecificHumidity\", \"H2Oc\", \"rho\", \"wv\", \"wv max\", \"wd\"]\n",
    "VAL_PCT  = .2\n",
    "TEST_PCT = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file and put into Dataframe\n",
    "fs = gcsfs.GCSFileSystem(project='TF images')\n",
    "f  = fs.open(FILE_PATH)\n",
    "df = pd.read_csv(f)\n",
    "#for col in df.columns: print(col)\n",
    "\n",
    "# Rename the columns (Not sure what all of them mean)\n",
    "df.columns = COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp in Kelvin is redundant\n",
    "del df[\"Temp(Kelv)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the label on the end\n",
    "tmp = df[\"Temp\"]\n",
    "del df[\"Temp\"]\n",
    "df[\"Temp\"] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(df[\"Temp\"])\n",
    "#for col in df.columns: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a sequence number to each observation (don't need date/time)\n",
    "intervals = [x for x in range(df.shape[0])]\n",
    "del df[\"DtTm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each column\n",
    "scaler = StandardScaler()\n",
    "data   = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = data.shape[0] * (1-VAL_PCT-TEST_PCT)\n",
    "trainIdx = int(idx)\n",
    "trainData = data[:trainIdx]\n",
    "idx = trainIdx + (VAL_PCT * data.shape[0])\n",
    "valIdx = int(idx)\n",
    "valData = data[trainIdx:valIdx]\n",
    "testData = data[valIdx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(hparams):\n",
    "    global SEQ_LEN, DEFAULTS, N_INPUTS\n",
    "    SEQ_LEN =  hparams['sequence_length']\n",
    "    DEFAULTS = [[0.0] for x in xrange(0, SEQ_LEN)]\n",
    "    N_INPUTS = SEQ_LEN - N_OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filename, mode, batch_size):\n",
    "    def _input_fn():\n",
    "        input_file_names = tf.train.match_filenames_once(filename)\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "            input_file_names, num_epochs=None, shuffle=True)\n",
    "        \n",
    "        reader = tf.TextLineReader()\n",
    "        _, value = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "        value_column = tf.expand_dims(value, -1)\n",
    "        #print ('readcsv={}'.format(value_column))\n",
    "    \n",
    "        # all_data is a list of tensors\n",
    "        all_data = tf.decode_csv(value_column, record_defaults=DEFAULTS)  \n",
    "        inputs = all_data[:len(all_data)-N_OUTPUTS]  # first few values\n",
    "        label = all_data[len(all_data)-N_OUTPUTS : ] # last few values\n",
    "    \n",
    "        # from list of tensors to tensor with one more dimension\n",
    "        inputs = tf.concat(inputs, axis=1)\n",
    "        label = tf.concat(label, axis=1)\n",
    "        #print ('inputs={}'.format(inputs))\n",
    "    \n",
    "        return {TIMESERIES_COL: inputs}, label   # dict of features, label\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the inference model\n",
    "def dnn_model(features, mode, params):\n",
    "    X = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS]) # flattened\n",
    "    h1 = tf.layers.dense(X, 10, activation=tf.nn.relu)\n",
    "    h2 = tf.layers.dense(h1, 3, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h2, 1, activation=None) # linear output: regression\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(features, mode, params):\n",
    "    X = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1]) # as a 1D \"image\" with a grayscale channel ?x10x1\n",
    "    c1 = tf.layers.max_pooling1d(\n",
    "        tf.layers.conv1d(X, filters=N_INPUTS//2,\n",
    "                         kernel_size=3, strides=1, # ?x10x5\n",
    "                         padding='same', activation=tf.nn.relu),\n",
    "        pool_size=2, strides=2\n",
    "    ) # ?x5x5\n",
    "    c2 = tf.layers.max_pooling1d(\n",
    "        tf.layers.conv1d(c1, filters=N_INPUTS//2,\n",
    "                         kernel_size=3, strides=1,\n",
    "                         padding='same', activation=tf.nn.relu),\n",
    "        pool_size=2, strides=2\n",
    "    ) # ?x2x5\n",
    "    outlen = (N_INPUTS//4) * (N_INPUTS//2)\n",
    "    c2flat = tf.reshape(c2, [-1, outlen])\n",
    "    h1 = tf.layers.dense(c2flat, 3, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None) # linear output: regression\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(features, mode, params):\n",
    "    LSTM_SIZE = N_INPUTS//3  # size of the internal state in each of the cells\n",
    "    # 1. dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
    "    \n",
    "    # 2. configure the RNN\n",
    "    lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    outputs = outputs[:, (N_INPUTS-1):, :]  # last cell only\n",
    "    \n",
    "    # 3. flatten lstm output and pass through a dense layer\n",
    "    lstm_flat = tf.reshape(outputs, [-1, lstm_cell.output_size])\n",
    "    h1 = tf.layers.dense(lstm_flat, N_INPUTS//2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None) # (?, 1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-layer LSTM\n",
    "def lstm2_model(features, mode, params):\n",
    "    # dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
    " \n",
    "    # 2. configure the RNN\n",
    "    lstm_cell1 = rnn.BasicLSTMCell(N_INPUTS*2, forget_bias=1.0)\n",
    "    lstm_cell2 = rnn.BasicLSTMCell(N_INPUTS//2, forget_bias=1.0)\n",
    "    lstm_cells = rnn.MultiRNNCell([lstm_cell1, lstm_cell2])\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cells, x, dtype=tf.float32)\n",
    "    outputs = outputs[:, (N_INPUTS-1):, :] # last one only\n",
    "\n",
    "    # 3. flatten lstm output and pass through a dense layer\n",
    "    lstm_flat = tf.reshape(outputs, [-1, lstm_cells.output_size])\n",
    "    h1 = tf.layers.dense(lstm_flat, lstm_cells.output_size//2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None) # (?, 1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create N-1 predictions\n",
    "def lstmN_model(features, mode, params):\n",
    "    # dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
    " \n",
    "    # 2. configure the RNN\n",
    "    lstm_cell1 = rnn.BasicLSTMCell(N_INPUTS*2, forget_bias=1.0)\n",
    "    lstm_cell2 = rnn.BasicLSTMCell(N_INPUTS//2, forget_bias=1.0)\n",
    "    lstm_cells = rnn.MultiRNNCell([lstm_cell1, lstm_cell2])\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cells, x, dtype=tf.float32)\n",
    "\n",
    "    # 3. make lstm output a 2D matrix and pass through a dense layer\n",
    "    # so that the dense layer is shared for all outputs\n",
    "    lstm_flat = tf.reshape(outputs, [-1, N_INPUTS, lstm_cells.output_size])\n",
    "    h1 = tf.layers.dense(lstm_flat, lstm_cells.output_size, activation=tf.nn.relu)\n",
    "    h2 = tf.layers.dense(h1, lstm_cells.output_size//2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h2, 1, activation=None) # (?, N_INPUTS, 1)\n",
    "    predictions = tf.reshape(predictions, [-1, N_INPUTS])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2])\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
