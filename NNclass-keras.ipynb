{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import layers\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadParms():\n",
    "    l1Size     = [18,12,6]\n",
    "    l2Size     = [6,3]\n",
    "    l3Size     = [4,2]\n",
    "    lr         = [2e-4]\n",
    "    Lambda     = [1e-4]          # Regularization parameter\n",
    "    batchSize  = [50]\n",
    "    epochs     = [10]\n",
    "    activation = [tf.nn.tanh]           # 'tanh' 'leakyReLU' 'ReLU' 'relu6' 'elu' 'crelu'\n",
    "    stdDev     = [0.2]\n",
    "    \n",
    "    return list(itertools.product(l1Size,\n",
    "                                  l2Size,\n",
    "                                  l3Size,\n",
    "                                  lr,\n",
    "                                  Lambda,\n",
    "                                  batchSize,\n",
    "                                  epochs,\n",
    "                                  activation,\n",
    "                                  stdDev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    folder = \"/home/tbrownex/data/test/\"\n",
    "    file   = \"autoEncoder.csv\"\n",
    "    df = pd.read_csv(folder+file,index_col=0)\n",
    "    cols = [\"v1\",\"v2\",\"v3\",\"v4\",\"v5\",\"v6\",\"v7\",\"v8\",\"v9\",\"label\"]\n",
    "    df.columns = cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(df):\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "    train = train[train['label'] == 0]     # Train on \"normal\" data only\n",
    "    del train[\"label\"]\n",
    "    del test[\"label\"]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    test  = scaler.transform(test)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLayers(parmDict):\n",
    "    nn = tf.keras.Sequential()\n",
    "    nn.add(layers.Dense(parmDict[\"l1Size\"], activation=parmDict[\"activation\"]))\n",
    "    nn.add(layers.Dense(parmDict[\"l2Size\"], activation=parmDict[\"activation\"]))\n",
    "    nn.add(layers.Dense(parmDict[\"l3Size\"], activation=parmDict[\"activation\"]))\n",
    "    nn.add(layers.Dense(parmDict[\"l2Size\"], activation=parmDict[\"activation\"]))\n",
    "    nn.add(layers.Dense(parmDict[\"l1Size\"], activation=parmDict[\"activation\"]))\n",
    "    nn.add(layers.Dense(9, activation=parmDict[\"activation\"]))\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildNetwork(parmDict):\n",
    "    nn = buildLayers(parmDict)\n",
    "    nn.compile(optimizer=tf.train.AdamOptimizer(parmDict[\"lr\"]),\\\n",
    "               loss='mse',\\\n",
    "               metrics=['accuracy'])\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitNetwork(nn):\n",
    "    return nn.fit(trainData, trainData,\\\n",
    "                  batch_size=32,\\\n",
    "                  epochs=40,\\\n",
    "                  validation_split=0.15,\\\n",
    "                  verbose=0,\\\n",
    "                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateNetwork(nn):\n",
    "    return nn.evaluate(x=testData,\\\n",
    "                       y=testData,\\\n",
    "                       verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrownex/tensorflow/lib/python3.5/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "df = getData()\n",
    "trainData, testData = prepData(df)\n",
    "\n",
    "parms = loadParms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parms                         mse     acc\n",
      "(18, 6, 4, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.008     0.989\n",
      "(18, 6, 2, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.017     0.969\n",
      "(18, 3, 4, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.017     0.969\n",
      "(18, 3, 2, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.021     0.969\n",
      "(12, 6, 4, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.016     0.969\n",
      "(12, 6, 2, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.017     0.969\n",
      "(12, 3, 4, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.016     0.969\n",
      "(12, 3, 2, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.015     0.982\n",
      "(6, 6, 4, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.026     0.969\n",
      "(6, 6, 2, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.021     0.969\n",
      "(6, 3, 4, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.026     0.969\n",
      "(6, 3, 2, 0.0002, 0.0001, 50, 10, <function tanh at 0x7f2bc09ea950>, 0.2)\n",
      "0.026     0.969\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<30}{:<8}{}\".format(\"parms\",\"mse\",\"acc\"))\n",
    "\n",
    "for x in parms:\n",
    "    parmDict = {}                  # holds the hyperparameter combination for one run\n",
    "    parmDict['l1Size']     = x[0]\n",
    "    parmDict['l2Size']     = x[1]\n",
    "    parmDict['l3Size']     = x[2]\n",
    "    parmDict['lr']         = x[3]\n",
    "    parmDict['lambda']     = x[4]\n",
    "    parmDict['batchSize']  = x[5]\n",
    "    parmDict['epochs']     = x[6]\n",
    "    parmDict['activation'] = x[7]\n",
    "    parmDict['stdDev']     = x[8]\n",
    "    \n",
    "    nn = buildNetwork(parmDict)\n",
    "    _ = fitNetwork(nn)\n",
    "    mse, acc = evaluateNetwork(nn)\n",
    "    print(x)\n",
    "    print(\"{:<10.3f}{:.3f}\".format(mse, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
