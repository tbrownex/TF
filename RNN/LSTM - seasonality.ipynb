{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "epochs = 80\n",
    "sequenceLength = 15\n",
    "stateSize = 12\n",
    "batchSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    return pd.read_csv(\"/home/tbrownex/data/test/seasonal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEvenBatches(df):\n",
    "    '''\n",
    "    Number of batches * sequence Length should be a multiple of the row count.\n",
    "    If not, get rid on any extras\n",
    "    '''    \n",
    "    extraRows = df.shape[0]%(batchSize*sequenceLength)\n",
    "    print(\"before: \", df.shape[0])\n",
    "    print(extraRows)\n",
    "    if extraRows > 0:\n",
    "        extraRows = int(extraRows)\n",
    "        print(\"{} rows removed to even the batches\".format(extraRows))\n",
    "        df = df[:-extraRows]\n",
    "    print(\"after: \", df.shape[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(df):\n",
    "    '''\n",
    "    Ignore \"date\" since this is univariate analysis\n",
    "    Both X and Y are based on X: Y is X shifted back \"sequenceLength\".\n",
    "    Y is shifted in order to associate training data and labels:\n",
    "       Y being shifted to the left represents the Future from the perspective of X\n",
    "    That \"future\" serves as the Label(s)\n",
    "    '''\n",
    "    x = df[\"value\"]\n",
    "    y = x[sequenceLength:].reset_index(drop=True)\n",
    "    x = x[:-sequenceLength]        # Make x and y the same length\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x = np.reshape(x, newshape=[batchSize, -1])\n",
    "    y = np.reshape(y, newshape=[batchSize, -1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(df):\n",
    "    '''\n",
    "    Make sure the batches are uniform sized\n",
    "    Format X and Y\n",
    "    '''\n",
    "    df = checkEvenBatches(df)\n",
    "    x,y = formatData(df)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  1000\n",
      "100\n",
      "100 rows removed to even the batches\n",
      "after:  900\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 885 into shape (10,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-95ff7bde0102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mafter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-7f088eb4e43c>\u001b[0m in \u001b[0;36mprepData\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckEvenBatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-73d08f8a3ee4>\u001b[0m in \u001b[0;36mformatData\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    255\u001b[0m            [5, 6]])\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 885 into shape (10,newaxis)"
     ]
    }
   ],
   "source": [
    "df = getData()\n",
    "x,y = prepData(df)\n",
    "after = x.shape[0] * x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWidth= x.shape[1]\n",
    "numBatches = dataWidth//sequenceLength\n",
    "print(\"{} batches of width {}\".format(numBatches, sequenceLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(tf.float32, [batchSize, sequenceLength], name=\"miniX\")\n",
    "batchY_placeholder = tf.placeholder(tf.float32, [batchSize, sequenceLength], name=\"miniY\")\n",
    "\n",
    "inputs_series = tf.split(batchX_placeholder, num_or_size_splits=sequenceLength, axis=1, name=\"inputs\")\n",
    "labels_series = tf.split(batchY_placeholder, num_or_size_splits=sequenceLength, axis=1, name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for b in range(numBatches):\n",
    "        start = b * sequenceLength\n",
    "        stop  = start + sequenceLength\n",
    "        miniX = x[:,start:stop]\n",
    "        miniY = y[:,start:stop]\n",
    "\n",
    "        inputs, labels = sess.run([inputs_series, labels_series],\n",
    "                                  feed_dict={\n",
    "                                      batchX_placeholder: miniX,\n",
    "                                      batchY_placeholder: miniY})\n",
    "        print(b)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellState = tf.placeholder(tf.float32, [batchSize, stateSize], name=\"cell\")\n",
    "hiddenState = tf.placeholder(tf.float32, [batchSize, stateSize], name=\"hidden\")\n",
    "init_state = tf.nn.rnn_cell.LSTMStateTuple(cellState, hiddenState)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(stateSize,1),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1)), dtype=tf.float32)\n",
    "\n",
    "# Forward passes\n",
    "#cell = tf.nn.rnn_cell.BasicLSTMCell(stateSize, state_is_tuple=True)\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units=stateSize, state_is_tuple=True)\n",
    "states_series, current_state = tf.nn.static_rnn(cell, inputs_series, init_state)\n",
    "\n",
    "predictions = [tf.matmul(state, W2) + b2 for state in states_series]\n",
    "loss = tf.losses.mean_squared_error(predictions, labels_series)\n",
    "training = tf.train.AdagradOptimizer(0.3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:<8}{}\".format(\"Epoch\", \"MSE\"))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        _current_cell_state = np.zeros((batchSize, stateSize))\n",
    "        _current_hidden_state = np.zeros((batchSize, stateSize))\n",
    "        predList = []      # This is to see what the predictions were for each mini batch\n",
    "        for b in range(numBatches):\n",
    "            start = b * sequenceLength\n",
    "            stop  = start + sequenceLength\n",
    "            miniX = x[:,start:stop]\n",
    "            miniY = y[:,start:stop]\n",
    "\n",
    "            _, _current_state, p = sess.run([training, current_state, predictions],\n",
    "                                         feed_dict={\n",
    "                                             batchX_placeholder: miniX,\n",
    "                                             batchY_placeholder: miniY,\n",
    "                                             cellState: _current_cell_state,\n",
    "                                             hiddenState: _current_hidden_state})\n",
    "\n",
    "            _current_cell_state, _current_hidden_state = _current_state\n",
    "            if b == 0:\n",
    "                predList.append(p)\n",
    "            \n",
    "        err = loss.eval(feed_dict={\n",
    "            batchX_placeholder: miniX,\n",
    "            batchY_placeholder: miniY,\n",
    "            cellState: _current_cell_state,\n",
    "            hiddenState: _current_hidden_state})\n",
    "        print(\"{:<8}{:,.0f}\".format(epoch, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predList[11][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
