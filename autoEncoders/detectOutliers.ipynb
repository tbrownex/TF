{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    folder = \"/home/tbrownex/data/test/\"\n",
    "    file   = \"autoEncoder.csv\"\n",
    "    df = pd.read_csv(folder+file,index_col=0)\n",
    "    cols = [\"v1\",\"v2\",\"v3\",\"v4\",\"v5\",\"v6\",\"v7\",\"v8\",\"v9\",\"label\"]\n",
    "    df.columns = cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(df):\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "    train = train[train['label'] == 0]     # Train on \"normal\" data only\n",
    "    del train[\"label\"]\n",
    "    del test[\"label\"]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    test  = scaler.transform(test)\n",
    "    train, val = train_test_split(train, test_size=0.1)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbrownex/tensorflow/lib/python3.5/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "df = getData()\n",
    "trainData, valData, testData = prepData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count = trainData.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN hyper-parameters\n",
    "inputSize   = feature_count\n",
    "l1Size      = 6\n",
    "l2Size      = 3\n",
    "l3Size      = 2\n",
    "l4Size      = l2Size\n",
    "l5Size      = l1Size\n",
    "outputSize  = inputSize\n",
    "\n",
    "lr          = .0002\n",
    "LAMBDA      = 10e-5          # Regularization parameter\n",
    "batchSize   = 50\n",
    "epochs      = 100\n",
    "activation  = ['tanh']           # 'tanh' 'leakyReLU' 'ReLU' 'relu6' 'elu' 'crelu'\n",
    "STD         = [0.2]\n",
    "\n",
    "actf = tf.nn.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the network\n",
    "tf.reset_default_graph()\n",
    "X  = tf.placeholder(\"float\", shape=[None, feature_count], name=\"input\")\n",
    "\n",
    "l1w = tf.Variable(tf.truncated_normal([feature_count, l1Size], stddev=STD, dtype=tf.float32))\n",
    "l2w = tf.Variable(tf.truncated_normal([l1Size, l2Size], stddev=STD, dtype=tf.float32))\n",
    "l3w = tf.Variable(tf.truncated_normal([l2Size, l3Size], stddev=STD, dtype=tf.float32))\n",
    "l4w = tf.Variable(tf.truncated_normal([l3Size, l4Size], stddev=STD, dtype=tf.float32))\n",
    "l5w = tf.Variable(tf.truncated_normal([l4Size, l5Size], stddev=STD, dtype=tf.float32))\n",
    "l6w = tf.Variable(tf.truncated_normal([l5Size, feature_count], stddev=STD, dtype=tf.float32))\n",
    "\n",
    "l1b = tf.Variable(tf.zeros(l1Size))\n",
    "l2b = tf.Variable(tf.zeros(l2Size))\n",
    "l3b = tf.Variable(tf.zeros(l3Size))\n",
    "l4b = tf.Variable(tf.zeros(l4Size))\n",
    "l5b = tf.Variable(tf.zeros(l5Size))\n",
    "l6b = tf.Variable(tf.zeros(feature_count))\n",
    "\n",
    "l1Out = actf(tf.matmul(X,l1w)+l1b)\n",
    "l2Out = actf(tf.matmul(l1Out,l2w)+l2b)\n",
    "l3Out = actf(tf.matmul(l2Out,l3w)+l3b)\n",
    "l4Out = actf(tf.matmul(l3Out,l4w)+l4b)\n",
    "l5Out = actf(tf.matmul(l4Out,l5w)+l5b)\n",
    "output = actf(tf.matmul(l5Out,l6w)+l6b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse      = tf.reduce_mean(tf.square(output - X))\n",
    "L1Layer1 = LAMBDA**tf.reduce_sum(tf.abs(l1w))\n",
    "L2Layer1 = LAMBDA*tf.nn.l2_loss(l1w)\n",
    "    \n",
    "cost = tf.reduce_mean(mse + L1Layer1 + L2Layer1)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train     = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 training batches of size 50\n"
     ]
    }
   ],
   "source": [
    "num_training_batches = int(trainData.shape[0] / batchSize)\n",
    "print(\"{} training batches of size {}\".format(num_training_batches, batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   Validation Loss\n",
      "0       0.505\n",
      "5       0.190\n",
      "10      0.049\n",
      "15      0.034\n",
      "20      0.030\n",
      "25      0.028\n",
      "30      0.028\n",
      "35      0.027\n",
      "40      0.027\n",
      "45      0.027\n",
      "50      0.027\n",
      "55      0.027\n",
      "60      0.027\n",
      "65      0.027\n",
      "70      0.027\n",
      "75      0.027\n",
      "80      0.027\n",
      "85      0.027\n",
      "90      0.027\n",
      "95      0.026\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(\"Epoch   Validation Loss\")\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        data = shuffle(trainData)\n",
    "        for j in range(num_training_batches):\n",
    "            x_mini = trainData[j*batchSize:j*batchSize+batchSize]\n",
    "            _ = sess.run(train, feed_dict = {X: x_mini})\n",
    "        if i % 5 == 0:\n",
    "            valLoss = sess.run(mse, feed_dict={X:valData})\n",
    "            print(\"{:<8}{:.3f}\".format(i, valLoss))\n",
    "    recreated = sess.run(output, feed_dict = {X: valData})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55, 0.92, 0.63, 0.46, 0.01, 0.78, 0.58, 0.75, 0.61],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recreated[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63, 1.  , 0.69, 0.78, 0.  , 0.87, 0.26, 0.94, 0.28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valData[0].round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
